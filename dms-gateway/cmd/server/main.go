package main

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"log"
	"log/slog"
	"net/http"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/segmentio/kafka-go"

	"go.opentelemetry.io/contrib/bridges/otelslog"
	"go.opentelemetry.io/contrib/instrumentation/github.com/gin-gonic/gin/otelgin"
	"go.opentelemetry.io/otel"
	"go.opentelemetry.io/otel/attribute"
	"go.opentelemetry.io/otel/codes"
	"go.opentelemetry.io/otel/exporters/otlp/otlplog/otlploggrpc"
	"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"
	"go.opentelemetry.io/otel/log/global"
	"go.opentelemetry.io/otel/propagation"
	sdklog "go.opentelemetry.io/otel/sdk/log"
	"go.opentelemetry.io/otel/sdk/resource"
	sdktrace "go.opentelemetry.io/otel/sdk/trace"
	semconv "go.opentelemetry.io/otel/semconv/v1.4.0"
	"go.opentelemetry.io/otel/trace"
)

const storageServiceURL = "http://localhost:8081/internal/process"

var tracer = otel.Tracer("dms-gateway")

type Job struct {
	Ctx    context.Context
	Title  string
	Author string
}

var jobQueue = make(chan Job, 100000)

func main() {
	ctx := context.Background()

	// ============================================
	// [ë³€ê²½] Redis Subscribe â†’ Kafka Consumer
	// ============================================
	// Kafka Reader (Consumer) ì´ˆê¸°í™”
	kafkaReader := kafka.NewReader(kafka.ReaderConfig{
		Brokers: []string{"localhost:9092"}, // Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
		Topic:   "task.complete",            // êµ¬ë…í•  Topic
		GroupID: "gateway-service-group",    // Consumer Group ID (ì¤‘ìš”!)

		// Consumer Group ì„¤ëª…:
		// - ê°™ì€ GroupIDë¥¼ ê°€ì§„ Consumerë“¤ì€ íŒŒí‹°ì…˜ì„ ë‚˜ëˆ ì„œ ì²˜ë¦¬
		// - ì˜ˆ: íŒŒí‹°ì…˜ 3ê°œ, Consumer 2ê°œ â†’ Consumer A(íŒŒí‹°ì…˜ 0,1), B(íŒŒí‹°ì…˜ 2)
		// - ë‹¤ë¥¸ GroupIDëŠ” ë…ë¦½ì ìœ¼ë¡œ ëª¨ë“  ë©”ì‹œì§€ ë°›ìŒ

		// ì½ê¸° ì„¤ì •
		MinBytes: 1,                      // ìµœì†Œ 1ë°”ì´íŠ¸ë§Œ ìˆì–´ë„ ê°€ì ¸ì˜´
		MaxBytes: 10e6,                   // í•œ ë²ˆì— ìµœëŒ€ 10MBê¹Œì§€ ì½ê¸°
		MaxWait:  500 * time.Millisecond, // ë©”ì‹œì§€ ì—†ìœ¼ë©´ 500ms ëŒ€ê¸°

		// ì˜¤í”„ì…‹ ì»¤ë°‹ ì„¤ì • (ì¤‘ìš”!)
		// ì˜¤í”„ì…‹ = "ì–´ë””ê¹Œì§€ ì½ì—ˆëŠ”ì§€" ê¸°ë¡
		CommitInterval: time.Second, // 1ì´ˆë§ˆë‹¤ ìë™ìœ¼ë¡œ ì˜¤í”„ì…‹ ì»¤ë°‹

		// ì‹œì‘ ìœ„ì¹˜ ì„¤ì •
		StartOffset: kafka.LastOffset, // ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì½ê¸° (ê¸°ë³¸ê°’)
		// StartOffset: kafka.FirstOffset,    // ì²˜ìŒë¶€í„° ì½ê¸° (ì¬ì²˜ë¦¬í•  ë•Œ)

		// ì—ëŸ¬ ì²˜ë¦¬
		MaxAttempts: 3, // ì½ê¸° ì‹¤íŒ¨ ì‹œ 3ë²ˆ ì¬ì‹œë„
	})
	defer kafkaReader.Close()

	// ============================================
	// [NEW] Kafka Consumer ê³ ë£¨í‹´
	// ê¸°ì¡´: Redis Subscribe goroutine
	// ë³€ê²½: Kafka ReadMessage loop
	// ============================================
	go func() {
		fmt.Println("ğŸ§ [Gateway] Kafka Consumer ì‹œì‘: task.complete êµ¬ë… ì¤‘...")

		for {
			// Kafkaì—ì„œ ë©”ì‹œì§€ ì½ê¸° (ë¸”ë¡œí‚¹ ë°©ì‹)
			// ë©”ì‹œì§€ê°€ ì˜¬ ë•Œê¹Œì§€ ì—¬ê¸°ì„œ ëŒ€ê¸°
			msg, err := kafkaReader.ReadMessage(context.Background())

			if err != nil {
				// ì½ê¸° ì‹¤íŒ¨ (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ, Kafka ë‹¤ìš´ ë“±)
				slog.Error("Kafka ì½ê¸° ì‹¤íŒ¨", "error", err)
				time.Sleep(time.Second) // 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
				continue
			}

			// ============================================
			// ë©”ì‹œì§€ ì²˜ë¦¬ (Redisì™€ ë™ì¼í•œ êµ¬ì¡°)
			// ============================================
			var result struct {
				TraceID string `json:"trace_id"`
				Status  string `json:"status"`
				Message string `json:"message"`
			}

			// JSON íŒŒì‹±
			if err := json.Unmarshal(msg.Value, &result); err != nil {
				slog.Error("JSON íŒŒì‹± ì‹¤íŒ¨",
					"error", err,
					"raw_message", string(msg.Value),
				)
				continue
			}

			// ë¡œê·¸ ì°ê¸° (Lokië¡œ ì „ì†¡)
			slog.Info("ğŸ“¥ [Kafka] ì‘ì—… ì™„ë£Œ ìˆ˜ì‹ !",
				"original_trace_id", result.TraceID,
				"status", result.Status,
				"msg_source", "kafka",
				"partition", msg.Partition, // ì–´ëŠ íŒŒí‹°ì…˜ì—ì„œ ì™”ëŠ”ì§€
				"offset", msg.Offset, // ì˜¤í”„ì…‹ (ìˆœì„œ ë²ˆí˜¸)
				"key", string(msg.Key), // Key ê°’
			)

			// ============================================
			// [ì°¸ê³ ] KafkaëŠ” ìë™ ì»¤ë°‹ë¨ (CommitInterval ì„¤ì •ì— ë”°ë¼)
			// RedisëŠ” Subscribeë§Œ í•˜ë©´ ëì´ì§€ë§Œ
			// KafkaëŠ” "ì–´ë””ê¹Œì§€ ì½ì—ˆëŠ”ì§€" ê¸°ë¡í•´ì•¼ ì¬ì‹œì‘ ì‹œ ì´ì–´ì„œ ì²˜ë¦¬ ê°€ëŠ¥
			// ============================================

			// ì—¬ê¸°ì„œ DB ì—…ë°ì´íŠ¸, ì›¹ì†Œì¼“ ì•Œë¦¼ ë“± ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
			// ...
		}
	}()

	// Trace ì´ˆê¸°í™”
	shutdown := initTracer()
	defer shutdown(context.Background())

	// Log ì´ˆê¸°í™”
	shutdownLogger := initLogger()
	defer shutdownLogger(ctx)

	logger := otelslog.NewLogger("dms-gateway-logger")
	slog.SetDefault(logger)

	// Worker Pool ì‹œì‘ (ë³€ê²½ ì—†ìŒ)
	for i := 0; i < 50; i++ {
		go worker(i)
	}

	r := gin.Default()
	r.Use(otelgin.Middleware("dms-gateway-server"))

	r.POST("/documents", func(c *gin.Context) {
		ctx := c.Request.Context()

		var req struct {
			Title  string `json:"title"`
			Author string `json:"author"`
		}

		if err := c.ShouldBindJSON(&req); err != nil {
			c.JSON(http.StatusBadRequest, gin.H{"error": "ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤."})
			return
		}

		span := trace.SpanFromContext(ctx)
		traceID := span.SpanContext().TraceID().String()
		fmt.Printf("[Gin] ë§¤ë‹ˆì €: ìš”ì²­ ì ‘ìˆ˜ (TraceID: %s)\n", traceID)

		slog.InfoContext(ctx, "ìš”ì²­ ì ‘ìˆ˜ ì™„ë£Œ",
			"doc_title", req.Title,
			"author", req.Author,
		)

		job := Job{
			Ctx:    ctx,
			Title:  req.Title,
			Author: req.Author,
		}

		select {
		case jobQueue <- job:
			c.JSON(http.StatusAccepted, gin.H{
				"status":   "QUEUED",
				"message":  "ìš”ì²­ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
				"trace_id": traceID,
			})
		default:
			c.JSON(http.StatusServiceUnavailable, gin.H{"error": "ì„œë²„ í˜¼ì¡"})
		}
	})

	// ============================================
	// [ì°¸ê³ ] HTTP ì½œë°± ì—”ë“œí¬ì¸íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ ê°€ëŠ¥
	// Kafka + HTTP ì½œë°± ë‘˜ ë‹¤ ì‚¬ìš©í•´ë„ ë¨
	// ============================================
	r.POST("/callbacks/task-complete", func(c *gin.Context) {
		var result struct {
			TraceID string `json:"trace_id"`
			Status  string `json:"status"`
			Message string `json:"message"`
		}
		if err := c.ShouldBindJSON(&result); err != nil {
			return
		}

		slog.InfoContext(c.Request.Context(), "ğŸ“¨ [Gateway] Workerë¡œë¶€í„° ì™„ë£Œ ë³´ê³  ìˆ˜ì‹ !",
			"original_trace_id", result.TraceID,
			"status", result.Status,
		)

		c.JSON(200, gin.H{"ack": "ok"})
	})

	fmt.Println("Gin gateway running on :8080")
	r.Run(":8080")
}

// Worker í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
func worker(id int) {
	client := &http.Client{Timeout: 10 * time.Second}

	for job := range jobQueue {
		childCtx, span := tracer.Start(job.Ctx, "async_worker_process",
			trace.WithAttributes(attribute.Int("worker_id", id)),
		)

		traceID := span.SpanContext().TraceID().String()
		fmt.Printf("[ì¼ê¾¼ %d] ì‘ì—… ì‹œì‘ TraceID: %s\n", id, traceID)

		payload, _ := json.Marshal(map[string]string{
			"doc_title": job.Title,
			"action":    "ARCHIVE_FAST",
		})

		req, _ := http.NewRequest("POST", storageServiceURL, bytes.NewBuffer(payload))
		req.Header.Set("Content-Type", "application/json")

		otel.GetTextMapPropagator().Inject(childCtx, propagation.HeaderCarrier(req.Header))

		resp, err := client.Do(req)
		if err != nil {
			span.RecordError(err)
			span.SetStatus(codes.Error, "HTTP call failed")
			slog.ErrorContext(childCtx, "Worker HTTP ìš”ì²­ ì‹¤íŒ¨", "worker_id", id, "error", err)
			span.End()
			continue
		}
		resp.Body.Close()

		fmt.Printf("[ì¼ê¾¼ %d] ì²˜ë¦¬ ì™„ë£Œ\n", id)
		slog.InfoContext(childCtx, "Worker ì²˜ë¦¬ ì™„ë£Œ", "worker_id", id)

		span.End()
	}
}

// Tracer ì´ˆê¸°í™” (ë³€ê²½ ì—†ìŒ)
func initTracer() func(context.Context) error {
	ctx := context.Background()

	exporter, err := otlptracegrpc.New(ctx,
		otlptracegrpc.WithInsecure(),
		otlptracegrpc.WithEndpoint("localhost:4317"),
	)
	if err != nil {
		log.Fatalf("OTLP Exporter ìƒì„± ì‹¤íŒ¨: %v", err)
	}

	res, err := resource.New(ctx,
		resource.WithAttributes(
			semconv.ServiceNameKey.String("dms-gateway-service"),
		),
	)
	if err != nil {
		log.Fatalf("Resource ìƒì„± ì‹¤íŒ¨: %v", err)
	}

	tp := sdktrace.NewTracerProvider(
		sdktrace.WithBatcher(exporter),
		sdktrace.WithResource(res),
	)

	otel.SetTracerProvider(tp)
	otel.SetTextMapPropagator(propagation.NewCompositeTextMapPropagator(
		propagation.TraceContext{},
		propagation.Baggage{},
	))

	return tp.Shutdown
}

// Logger ì´ˆê¸°í™” (ë³€ê²½ ì—†ìŒ)
func initLogger() func(context.Context) error {
	ctx := context.Background()

	exporter, err := otlploggrpc.New(ctx,
		otlploggrpc.WithInsecure(),
		otlploggrpc.WithEndpoint("localhost:4317"),
	)
	if err != nil {
		log.Fatalf("Log Exporter ì—ëŸ¬: %v", err)
	}

	res, _ := resource.New(ctx,
		resource.WithAttributes(
			semconv.ServiceNameKey.String("dms-gateway"),
		),
	)

	lp := sdklog.NewLoggerProvider(
		sdklog.WithProcessor(sdklog.NewBatchProcessor(exporter)),
		sdklog.WithResource(res),
	)

	global.SetLoggerProvider(lp)

	return lp.Shutdown
}
